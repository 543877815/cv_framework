{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:113: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  warnings.warn(\"\"\"Parent poll failed.  If the frontend dies,\n"
     ]
    }
   ],
   "source": [
    "def get_platform_path():\n",
    "    system = platform.system()\n",
    "    data_dir, model_dir, checkpoint_dir, dirs = '', '', '', []\n",
    "    if system == 'Windows':\n",
    "        drive, common_dir = 'F', 'cache'\n",
    "        data_dir = '{}:\\\\{}\\\\data'.format(drive, common_dir)\n",
    "        model_dir = '{}:\\\\{}\\\\model'.format(drive, common_dir)\n",
    "        checkpoint_dir = '{}:\\\\{}\\\\checkpoint'.format(drive, common_dir)\n",
    "        dirs = [data_dir, model_dir, checkpoint_dir]\n",
    "\n",
    "    elif system == 'Linux':\n",
    "        common_dir = '/data'\n",
    "        data_dir = '{}/data'.format(common_dir)\n",
    "        model_dir = '{}/model'.format(common_dir)\n",
    "        checkpoint_dir = '{}/checkpoint'.format(common_dir)\n",
    "        dirs = [data_dir, model_dir, checkpoint_dir]\n",
    "\n",
    "    for dir in dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "\n",
    "    return data_dir, model_dir, checkpoint_dir\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_collate_fn(batch_lst, reshape_size=224):\n",
    "    preprocess = transforms.Compose([\n",
    "      transforms.Resize((reshape_size, reshape_size)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "      ])\n",
    "    \n",
    "    batch_size = len(batch_lst)\n",
    "    \n",
    "    img_batch = torch.zeros(batch_size, 3, reshape_size, reshape_size)\n",
    "    \n",
    "    max_num_box = max(len(batch_lst[i][1]['annotation']['object']) \\\n",
    "                      for i in range(batch_size))\n",
    "\n",
    "    box_batch = torch.Tensor(batch_size, max_num_box, 5).fill_(-1.)\n",
    "    w_list = []\n",
    "    h_list = []\n",
    "    img_id_list = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img, ann = batch_lst[i]\n",
    "        w_list.append(img.size[0]) # image width\n",
    "        h_list.append(img.size[1]) # image height\n",
    "        img_id_list.append(ann['annotation']['filename'])\n",
    "        img_batch[i] = preprocess(img)\n",
    "        all_bbox = ann['annotation']['object']\n",
    "        if type(all_bbox) == dict: # inconsistency in the annotation file\n",
    "            all_bbox = [all_bbox]\n",
    "        for bbox_idx, one_bbox in enumerate(all_bbox):\n",
    "            bbox = one_bbox['bndbox']\n",
    "            obj_cls = one_bbox['name']\n",
    "            box_batch[i][bbox_idx] = torch.Tensor([float(bbox['xmin']), float(bbox['ymin']),\n",
    "              float(bbox['xmax']), float(bbox['ymax']), class_to_idx[obj_cls]])\n",
    "    \n",
    "    h_batch = torch.tensor(h_list)\n",
    "    w_batch = torch.tensor(w_list)\n",
    "\n",
    "    return img_batch, box_batch, w_batch, h_batch, img_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using downloaded and verified file: F:\\cache\\data\\VOCtrainval_11-May-2012.tar\n",
      "Using downloaded and verified file: F:\\cache\\data\\VOCtrainval_11-May-2012.tar\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import argparse\n",
    "import platform\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Pytorch YOLOv1 Training\")\n",
    "\n",
    "#     parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "#     parser.add_argument('--epoch', default=200, type=int, help='epoch')\n",
    "#     parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "#     parser.add_argument('--use_cuda', action='store_true', default=True, help='whether to use cuda')\n",
    "#     parser.add_argument('--net', default='resnet18', help='network type')\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "    use_cuda = True\n",
    "    \n",
    "    # detect device\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "    # data/model/checkpoint in different platform\n",
    "    data_dir, model_dir, checkpoint_dir = get_platform_path()\n",
    "\n",
    "    # dataset VOC2011 and others are subset of VOC2012\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.VOCDetection(root=data_dir, download=True, year='2012',\n",
    "                                                 image_set='train', transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4, collate_fn=voc_collate_fn)\n",
    "\n",
    "    valset = torchvision.datasets.VOCDetection(root=data_dir, download=True, year='2012',\n",
    "                                               image_set='val', transform=transform_val)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {'aeroplane':0, 'bicycle':1, 'bird':2, 'boat':3, 'bottle':4,\n",
    "                'bus':5, 'car':6, 'cat':7, 'chair':8, 'cow':9, 'diningtable':10,\n",
    "                'dog':11, 'horse':12, 'motorbike':13, 'person':14, 'pottedplant':15,\n",
    "                'sheep':16, 'sofa':17, 'train':18, 'tvmonitor':19\n",
    "}\n",
    "idx_to_class = {i:c for c, i in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 16272, 18544, 12072, 19068) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-278e5550635a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_id_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_id_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 16272, 18544, 12072, 19068) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for batch_idx,(img_batch, box_batch, w_batch, h_batch, img_id_list) in trainloader:\n",
    "    print(img_batch, box_batch, w_batch, h_batch, img_id_list)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
