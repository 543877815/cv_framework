{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:113: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  warnings.warn(\"\"\"Parent poll failed.  If the frontend dies,\n"
     ]
    }
   ],
   "source": [
    "def get_platform_path():\n",
    "    system = platform.system()\n",
    "    data_dir, model_dir, checkpoint_dir, dirs = '', '', '', []\n",
    "    if system == 'Windows':\n",
    "        drive, common_dir = 'F', 'cache'\n",
    "        data_dir = '{}:\\\\{}\\\\data'.format(drive, common_dir)\n",
    "        model_dir = '{}:\\\\{}\\\\model'.format(drive, common_dir)\n",
    "        checkpoint_dir = '{}:\\\\{}\\\\checkpoint'.format(drive, common_dir)\n",
    "        dirs = [data_dir, model_dir, checkpoint_dir]\n",
    "\n",
    "    elif system == 'Linux':\n",
    "        common_dir = '/data'\n",
    "        data_dir = '{}/data'.format(common_dir)\n",
    "        model_dir = '{}/model'.format(common_dir)\n",
    "        checkpoint_dir = '{}/checkpoint'.format(common_dir)\n",
    "        dirs = [data_dir, model_dir, checkpoint_dir]\n",
    "\n",
    "    for dir in dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "\n",
    "    return data_dir, model_dir, checkpoint_dir\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_collate_fn(batch_lst, reshape_size=224):\n",
    "    preprocess = transforms.Compose([\n",
    "      transforms.Resize((reshape_size, reshape_size)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "      ])\n",
    "    \n",
    "    batch_size = len(batch_lst)\n",
    "    \n",
    "    img_batch = torch.zeros(batch_size, 3, reshape_size, reshape_size)\n",
    "    \n",
    "    max_num_box = max(len(batch_lst[i][1]['annotation']['object']) \\\n",
    "                      for i in range(batch_size))\n",
    "\n",
    "    box_batch = torch.Tensor(batch_size, max_num_box, 5).fill_(-1.)\n",
    "    w_list = []\n",
    "    h_list = []\n",
    "    img_id_list = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img, ann = batch_lst[i]\n",
    "        w_list.append(img.size[0]) # image width\n",
    "        h_list.append(img.size[1]) # image height\n",
    "        img_id_list.append(ann['annotation']['filename'])\n",
    "        img_batch[i] = preprocess(img)\n",
    "        all_bbox = ann['annotation']['object']\n",
    "        if type(all_bbox) == dict: # inconsistency in the annotation file\n",
    "            all_bbox = [all_bbox]\n",
    "        for bbox_idx, one_bbox in enumerate(all_bbox):\n",
    "            bbox = one_bbox['bndbox']\n",
    "            obj_cls = one_bbox['name']\n",
    "            box_batch[i][bbox_idx] = torch.Tensor([float(bbox['xmin']), float(bbox['ymin']),\n",
    "              float(bbox['xmax']), float(bbox['ymax']), class_to_idx[obj_cls]])\n",
    "    \n",
    "    h_batch = torch.tensor(h_list)\n",
    "    w_batch = torch.tensor(w_list)\n",
    "\n",
    "    return img_batch, box_batch, w_batch, h_batch, img_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using downloaded and verified file: F:\\cache\\data\\VOCtrainval_11-May-2012.tar\n",
      "Using downloaded and verified file: F:\\cache\\data\\VOCtrainval_11-May-2012.tar\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import argparse\n",
    "import platform\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Pytorch YOLOv1 Training\")\n",
    "\n",
    "#     parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "#     parser.add_argument('--epoch', default=200, type=int, help='epoch')\n",
    "#     parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "#     parser.add_argument('--use_cuda', action='store_true', default=True, help='whether to use cuda')\n",
    "#     parser.add_argument('--net', default='resnet18', help='network type')\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "    use_cuda = True\n",
    "    \n",
    "    # detect device\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "    # data/model/checkpoint in different platform\n",
    "    data_dir, model_dir, checkpoint_dir = get_platform_path()\n",
    "\n",
    "    # dataset VOC2011 and others are subset of VOC2012\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.VOCDetection(root=data_dir, download=True, year='2012',\n",
    "                                                 image_set='train', transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "    valset = torchvision.datasets.VOCDetection(root=data_dir, download=True, year='2012',\n",
    "                                               image_set='val', transform=transform_val)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 81, in default_collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7f6ba407cd46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"D:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 81, in default_collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,(inputs, targets) in trainloader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
